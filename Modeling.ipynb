{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1be5851-a6d8-4a98-ae50-e3b218aee1a8",
   "metadata": {},
   "source": [
    "# Primitive Modeling\n",
    "The data processing involved:\n",
    "- removing a few outliers\n",
    "- dropping unnecessary features\n",
    "- dropping rows with high missingness\n",
    "- imputing/interpolating remaining missing values\n",
    "\n",
    "We are going to try fitting as simple regression model to get a baseline, and then we will try more complex methods to:\n",
    "- Transform the feature space\n",
    "- Deal with missing values\n",
    "- Overcome imbalanced classes (may not be necessary if regression and thresholding works)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d465594-f0f6-4ad2-8d53-80ca31bb8839",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35d95382-cde2-4ed4-8c68-e8437b267481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1dc3a57-12bd-4f48-a686-41e429f4cb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read survey\n",
    "data_dictionary = pd.read_csv('data/data_dictionary.csv')\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "\n",
    "# read aggregated actigraphy\n",
    "actigraphy_data = pd.read_csv('data/PA_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9a63349b-3a68-4c98-a27b-fb262a1f5706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "809 rows dropped because 50% or more of the data was missing.\n",
      "There are 1928 rows remaining in the train data.\n",
      "This is the proportion of data available per feature. It might be wise to drop features with high missingness. We can try both ways though.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Physical-Waist_Circumference              0.213174\n",
       "Fitness_Endurance-Total_Time_sec          0.335062\n",
       "FGC-FGC_GSD                               0.404046\n",
       "FGC-FGC_GSND                              0.404046\n",
       "vigorous                                  0.418568\n",
       "moderate                                  0.429979\n",
       "light                                     0.430498\n",
       "sendentary                                0.430498\n",
       "PAQ-PAQ_Total                             0.672199\n",
       "FGC-FGC_PU                                0.860477\n",
       "FGC-FGC_SRL                               0.860996\n",
       "FGC-FGC_SRR                               0.862033\n",
       "FGC-FGC_CU                                0.863589\n",
       "FGC-FGC_TL                                0.864108\n",
       "CGAS-CGAS_Score                           0.880705\n",
       "SDS-SDS_Total_T                           0.906639\n",
       "BIA-BIA_LST                               0.939315\n",
       "BIA-BIA_SMM                               0.939315\n",
       "BIA-BIA_TBW                               0.939315\n",
       "BIA-BIA_LDM                               0.939315\n",
       "BIA-BIA_ICW                               0.939315\n",
       "BIA-BIA_Fat                               0.939315\n",
       "BIA-BIA_FMI                               0.939315\n",
       "BIA-BIA_FFMI                              0.939315\n",
       "BIA-BIA_BMR                               0.939315\n",
       "BIA-BIA_ECW                               0.939315\n",
       "BIA-BIA_DEE                               0.939315\n",
       "BIA-BIA_BMI                               0.939315\n",
       "BIA-BIA_BMC                               0.939315\n",
       "BIA-BIA_FFM                               0.939315\n",
       "BIA-BIA_Frame_num                         0.939834\n",
       "BIA-BIA_Activity_Level_num                0.939834\n",
       "PreInt_EduHx-computerinternet_hoursday    0.979772\n",
       "Physical-Diastolic_BP                     0.980290\n",
       "Physical-Systolic_BP                      0.980290\n",
       "Physical-HeartRate                        0.983402\n",
       "Physical-Weight                           0.995332\n",
       "Physical-BMI                              0.995332\n",
       "Physical-Height                           0.996369\n",
       "sii                                       1.000000\n",
       "Basic_Demos-Sex                           1.000000\n",
       "Basic_Demos-Age                           1.000000\n",
       "id                                        1.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final length of the training dataset: 1928\n"
     ]
    }
   ],
   "source": [
    "# Outliers ----------------------------------------------------------------------------\n",
    "# removing outliers (should change this to be automatic so it applies to the test data)\n",
    "# From CGAS\n",
    "train_data.loc[2065, 'CGAS-CGAS_Score'] = 99\n",
    "# From BIA (there might still be some suspicious extreme values)\n",
    "cols = data_dictionary.loc[(data_dictionary['Instrument'] == 'Bio-electric Impedance Analysis') & (data_dictionary['Type'] == 'float'), 'Field']\n",
    "train_data.loc[[3205, 3511], cols] = np.nan # remove 3511 and 3205's BIA values because they seem wrong. They have normal heights and weights but extreme values for BIA measures\n",
    "\n",
    "# Drop features ----------------------------------------------------------------------\n",
    "# combine FitnessGram Minutes and seconds\n",
    "train_data['Fitness_Endurance-Total_Time_sec'] = train_data['Fitness_Endurance-Time_Mins'] * 60 + train_data['Fitness_Endurance-Time_Sec'] # remove remaining Fitness_Endurance Columns\n",
    "# drop all PCIAT columns, any column that ends in -Season, FitnessGram Zones, remaining Fitness_Endurance columns, and redundant SDS column\n",
    "columns_to_drop = [col for col in train_data.columns if col.startswith('PCIAT') or col.endswith('Season') or col.endswith('Zone')]\n",
    "columns_to_drop.extend(['Fitness_Endurance-Max_Stage', 'Fitness_Endurance-Time_Sec', 'Fitness_Endurance-Time_Mins', 'SDS-SDS_Total_Raw'])\n",
    "train_data_cleaned = train_data.drop(columns=columns_to_drop)\n",
    "\n",
    "# merge PAQ_A and PAQ_C\n",
    "# keep adolescent value if 13 or older\n",
    "train_data_cleaned.loc[train_data_cleaned['PAQ_A-PAQ_A_Total'].notna() & train_data_cleaned['PAQ_C-PAQ_C_Total'].notna() & (train_data_cleaned['Basic_Demos-Age'] >= 13), 'PAQ_C-PAQ_C_Total'] = np.nan\n",
    "# keep child value is younger than 13\n",
    "train_data_cleaned.loc[train_data_cleaned['PAQ_A-PAQ_A_Total'].notna() & train_data_cleaned['PAQ_C-PAQ_C_Total'].notna() & (train_data_cleaned['Basic_Demos-Age'] < 13), 'PAQ_A-PAQ_A_Total'] = np.nan\n",
    "# merge columns\n",
    "train_data_cleaned['PAQ-PAQ_Total'] = train_data_cleaned['PAQ_A-PAQ_A_Total'].fillna(train_data_cleaned['PAQ_C-PAQ_C_Total'])\n",
    "# drop columns\n",
    "train_data_cleaned = train_data_cleaned.drop(columns = ['PAQ_A-PAQ_A_Total', 'PAQ_C-PAQ_C_Total'])\n",
    "\n",
    "# include aggregate acitgraphy features\n",
    "train_data_cleaned = pd.merge(train_data_cleaned, actigraphy_data, left_on='id', how='left', right_index=True)\n",
    "\n",
    "# Missing Values (might not have to handle completely manually for CATBoost, though it could improve performance) -----------\n",
    "# Drop rows with high missingness (should investigate characteristics of rows with high missingness)\n",
    "thresh = 50\n",
    "percent_missing_per_row = train_data_cleaned.isnull().mean(axis=1) * 100\n",
    "high_missingness_idx = percent_missing_per_row[percent_missing_per_row > thresh].index.values\n",
    "train_data_cleaned = train_data_cleaned.drop(high_missingness_idx)\n",
    "print(f'{len(high_missingness_idx)} rows dropped because {thresh}% or more of the data was missing.')\n",
    "print(f'There are {len(train_data_cleaned)} rows remaining in the train data.')\n",
    "\n",
    "# Drop features with high missingness?\n",
    "print('This is the proportion of data available per feature. It might be wise to drop features with high missingness. We can try both ways though.')\n",
    "display(train_data_cleaned.notna().mean().sort_values())\n",
    "\n",
    "# Impute/interpolate remaining missing values (not necessary for CATBoost)\n",
    "\n",
    "# Convert categorical columns to the correct data type? Since their ordinal, it might work to not convert\n",
    "# use data dictionary to convert features that have type==\"categorical int\" into str dtype\n",
    "\n",
    "# drop rows without target\n",
    "train_data_cleaned = train_data_cleaned.dropna(subset='sii')\n",
    "print(f'Final length of the training dataset: {len(train_data_cleaned)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575bb10a-9217-406c-abe8-c9b0cf93b39d",
   "metadata": {},
   "source": [
    "## CAT Boost\n",
    "Will automatically handle the categorical features. No need for one-hot encoding. Have to convert the categorical features to str though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2a85cc60-a441-41d7-8373-8ee96a29bbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, root_mean_squared_error, r2_score\n",
    "from catboost import CatBoostRegressor\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3697811-3ffd-4d61-82d0-aea3ff7e026a",
   "metadata": {},
   "source": [
    "Should optimize hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b865fd06-ae54-4064-a080-d5d685331c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.7583334\ttotal: 3.9ms\tremaining: 386ms\n",
      "10:\tlearn: 0.6802886\ttotal: 20.7ms\tremaining: 167ms\n",
      "20:\tlearn: 0.6416826\ttotal: 31.9ms\tremaining: 120ms\n",
      "30:\tlearn: 0.6159614\ttotal: 43.5ms\tremaining: 96.8ms\n",
      "40:\tlearn: 0.5954498\ttotal: 54ms\tremaining: 77.7ms\n",
      "50:\tlearn: 0.5798528\ttotal: 64.7ms\tremaining: 62.2ms\n",
      "60:\tlearn: 0.5676271\ttotal: 75.7ms\tremaining: 48.4ms\n",
      "70:\tlearn: 0.5520926\ttotal: 88.4ms\tremaining: 36.1ms\n",
      "80:\tlearn: 0.5424177\ttotal: 98.4ms\tremaining: 23.1ms\n",
      "90:\tlearn: 0.5306812\ttotal: 109ms\tremaining: 10.7ms\n",
      "99:\tlearn: 0.5181189\ttotal: 118ms\tremaining: 0us\n",
      "Mean Absolute Error (MAE): 0.5387\n",
      "Mean Squared Error (MSE): 0.4636\n",
      "Root Mean Squared Error (RMSE): 0.6809\n",
      "R-squared (R²): 0.2311\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SDS-SDS_Total_T</td>\n",
       "      <td>13.390361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>PreInt_EduHx-computerinternet_hoursday</td>\n",
       "      <td>12.246025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Basic_Demos-Age</td>\n",
       "      <td>5.086482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Physical-Height</td>\n",
       "      <td>4.167854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Physical-HeartRate</td>\n",
       "      <td>3.175268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CGAS-CGAS_Score</td>\n",
       "      <td>2.927390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Basic_Demos-Sex</td>\n",
       "      <td>2.923253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Physical-Systolic_BP</td>\n",
       "      <td>2.888344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FGC-FGC_TL</td>\n",
       "      <td>2.860958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FGC-FGC_CU</td>\n",
       "      <td>2.818706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FGC-FGC_GSD</td>\n",
       "      <td>2.802829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>FGC-FGC_SRR</td>\n",
       "      <td>2.388354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FGC-FGC_PU</td>\n",
       "      <td>2.313136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Physical-Waist_Circumference</td>\n",
       "      <td>2.207694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Physical-BMI</td>\n",
       "      <td>2.158446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BIA-BIA_Activity_Level_num</td>\n",
       "      <td>2.042481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FGC-FGC_GSND</td>\n",
       "      <td>2.018721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Physical-Weight</td>\n",
       "      <td>1.979719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>BIA-BIA_Fat</td>\n",
       "      <td>1.944528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>BIA-BIA_FFM</td>\n",
       "      <td>1.797235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>sendentary</td>\n",
       "      <td>1.785863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BIA-BIA_BMC</td>\n",
       "      <td>1.719904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FGC-FGC_SRL</td>\n",
       "      <td>1.699322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>BIA-BIA_LDM</td>\n",
       "      <td>1.664706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>PAQ-PAQ_Total</td>\n",
       "      <td>1.608535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>BIA-BIA_DEE</td>\n",
       "      <td>1.598709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>BIA-BIA_BMR</td>\n",
       "      <td>1.595541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>vigorous</td>\n",
       "      <td>1.580834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BIA-BIA_FFMI</td>\n",
       "      <td>1.349798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>BIA-BIA_TBW</td>\n",
       "      <td>1.320168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>BIA-BIA_FMI</td>\n",
       "      <td>1.289423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>light</td>\n",
       "      <td>1.272732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Physical-Diastolic_BP</td>\n",
       "      <td>1.155025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BIA-BIA_BMI</td>\n",
       "      <td>1.124062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>BIA-BIA_LST</td>\n",
       "      <td>1.056051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BIA-BIA_ECW</td>\n",
       "      <td>1.035646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>moderate</td>\n",
       "      <td>0.940013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>BIA-BIA_SMM</td>\n",
       "      <td>0.774789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>BIA-BIA_Frame_num</td>\n",
       "      <td>0.634174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BIA-BIA_ICW</td>\n",
       "      <td>0.513850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Fitness_Endurance-Total_Time_sec</td>\n",
       "      <td>0.143073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Feature  Importance\n",
       "33                         SDS-SDS_Total_T   13.390361\n",
       "34  PreInt_EduHx-computerinternet_hoursday   12.246025\n",
       "0                          Basic_Demos-Age    5.086482\n",
       "4                          Physical-Height    4.167854\n",
       "8                       Physical-HeartRate    3.175268\n",
       "2                          CGAS-CGAS_Score    2.927390\n",
       "1                          Basic_Demos-Sex    2.923253\n",
       "9                     Physical-Systolic_BP    2.888344\n",
       "16                              FGC-FGC_TL    2.860958\n",
       "10                              FGC-FGC_CU    2.818706\n",
       "12                             FGC-FGC_GSD    2.802829\n",
       "15                             FGC-FGC_SRR    2.388354\n",
       "13                              FGC-FGC_PU    2.313136\n",
       "6             Physical-Waist_Circumference    2.207694\n",
       "3                             Physical-BMI    2.158446\n",
       "17              BIA-BIA_Activity_Level_num    2.042481\n",
       "11                            FGC-FGC_GSND    2.018721\n",
       "5                          Physical-Weight    1.979719\n",
       "26                             BIA-BIA_Fat    1.944528\n",
       "23                             BIA-BIA_FFM    1.797235\n",
       "37                              sendentary    1.785863\n",
       "18                             BIA-BIA_BMC    1.719904\n",
       "14                             FGC-FGC_SRL    1.699322\n",
       "29                             BIA-BIA_LDM    1.664706\n",
       "36                           PAQ-PAQ_Total    1.608535\n",
       "21                             BIA-BIA_DEE    1.598709\n",
       "20                             BIA-BIA_BMR    1.595541\n",
       "40                                vigorous    1.580834\n",
       "24                            BIA-BIA_FFMI    1.349798\n",
       "32                             BIA-BIA_TBW    1.320168\n",
       "25                             BIA-BIA_FMI    1.289423\n",
       "38                                   light    1.272732\n",
       "7                    Physical-Diastolic_BP    1.155025\n",
       "19                             BIA-BIA_BMI    1.124062\n",
       "30                             BIA-BIA_LST    1.056051\n",
       "22                             BIA-BIA_ECW    1.035646\n",
       "39                                moderate    0.940013\n",
       "31                             BIA-BIA_SMM    0.774789\n",
       "27                       BIA-BIA_Frame_num    0.634174\n",
       "28                             BIA-BIA_ICW    0.513850\n",
       "35        Fitness_Endurance-Total_Time_sec    0.143073"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = train_data_cleaned.drop(['id','sii'], axis=1)\n",
    "y = train_data_cleaned['sii']\n",
    "\n",
    "train_data_cleaned['Basic_Demos-Sex'] = train_data_cleaned['Basic_Demos-Sex'].astype(str) # technically already dummy coded, so don't have to do \n",
    "categorical_features = ['Basic_Demos-Sex'] # can add to this\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = CatBoostRegressor(iterations=100, depth=6, learning_rate=0.1, verbose=10) # cat_features=categorical_features (had issues)\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the regression model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print regression metrics\n",
    "print(f'Mean Absolute Error (MAE): {mae:.4f}')\n",
    "print(f'Mean Squared Error (MSE): {mse:.4f}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse:.4f}')\n",
    "print(f'R-squared (R²): {r2:.4f}')\n",
    "\n",
    "# Get feature importance\n",
    "feature_importances = model.get_feature_importance()\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "display(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8ce50eaa-5997-4293-a813-e03dcae13eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5440414507772021"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to classes\n",
    "y_pred = y_pred.round()\n",
    "y_pred[y_pred <= 0] = 0\n",
    "y_pred[y_pred > 3] = 3\n",
    "acc = (y_pred == y_test).mean()\n",
    "print(f'Accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738de914-ae8a-4c52-b1a1-bad765ee9a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try CatBoostClassifier too"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8706d7ae-bc7c-46f5-81be-5867b2af756b",
   "metadata": {},
   "source": [
    "## CNN on time series\n",
    "\n",
    "**Steps to Build a CNN for Time Series**\n",
    "1. Prepare the Data\n",
    "    - Shape the Input: CNNs for time series require input of shape (samples, timesteps, features):\n",
    "        - samples: Number of data points or observations.\n",
    "        - timesteps: Length of the time series for each sample.\n",
    "        - features: Number of features per timestep.\n",
    "    For a univariate time series, features=1.\n",
    "    - Split into Training and Testing Sets:\n",
    "        - Ensure a robust split, often chronological (e.g., train on earlier data and test on later).\n",
    "    - Scale the Data:\n",
    "        - Normalize or standardize the data for better convergence.\n",
    "2. Build the CNN\n",
    "3. Adjust hyperparameters\n",
    "    - Filters\n",
    "    - Kernel Size\n",
    "    - Pooling Size\n",
    "    - Stride\n",
    "5. Evaluate and tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908f3534-d76f-4454-b11e-aa36a0868d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "\n",
    "# Create a CNN model\n",
    "model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(timesteps, features)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1)  # Output layer (adjust units and activation for specific tasks)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c29c28-03bd-4435-bb69-4095c37db171",
   "metadata": {},
   "source": [
    "## Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6770b191-f7b9-46b5-b2c6-21241a3f71c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
